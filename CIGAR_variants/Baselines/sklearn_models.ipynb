{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8f4fadd3-7e12-4f61-9d2f-2971cc5b426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pprint\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74cc1e47-c6b7-4228-8540-8f78f43d6d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff8a0123-fc62-40ba-8c07-86c8c3356ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_action_name_train = (\n",
    "                pd.read_csv(DATA_DIR / 'action_features_train.csv.gz', index_col = [0])\n",
    "                .sort_values(by=['names_number'],ascending=False)\n",
    "                #.head(100)\n",
    "            )\n",
    "\n",
    "df_action_name_test = (\n",
    "                pd.read_csv(DATA_DIR / 'action_test.csv.gz', index_col = [0])\n",
    "                .sort_values(by=['names_number'],ascending=False)\n",
    "                .head(100)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22be8fb5-e7ad-46e7-b75d-b0a4058e138e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# initialize the RoBERTa based model. \n",
    "\n",
    "import torch\n",
    "from transformers import (WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup,\n",
    "                          BertConfig, BertForMaskedLM, BertTokenizer,\n",
    "                          GPT2Config, GPT2LMHeadModel, GPT2Tokenizer,\n",
    "                          OpenAIGPTConfig, OpenAIGPTLMHeadModel, OpenAIGPTTokenizer,\n",
    "                          RobertaConfig, RobertaModel, RobertaTokenizer,\n",
    "                          DistilBertConfig, DistilBertForMaskedLM, DistilBertTokenizer)\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    'gpt2': (GPT2Config, GPT2LMHeadModel, GPT2Tokenizer),\n",
    "    'openai-gpt': (OpenAIGPTConfig, OpenAIGPTLMHeadModel, OpenAIGPTTokenizer),\n",
    "    'bert': (BertConfig, BertForMaskedLM, BertTokenizer),\n",
    "    'roberta': (RobertaConfig, RobertaModel, RobertaTokenizer),\n",
    "    'distilbert': (DistilBertConfig, DistilBertForMaskedLM, DistilBertTokenizer)\n",
    "}\n",
    "\n",
    "\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES['roberta']\n",
    "\n",
    "config = config_class.from_pretrained(\"roberta-base\")\n",
    "tokenizer = tokenizer_class.from_pretrained(\"roberta-base\")\n",
    "encoder = model_class.from_pretrained(\"roberta-base\", config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12eee97a-5fae-4f42-ac87-94cb5a023e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrase_tokenization(phrase, tokenizer, max_token_length):\n",
    "    \n",
    "    '''This function tokenize the phrases into ids'''\n",
    "    \n",
    "    phrase_tokens = tokenizer.tokenize(phrase)\n",
    "    phrase_tokens = phrase_tokens[:max_token_length-2]\n",
    "    phrase_tokens = [tokenizer.cls_token]+phrase_tokens+[tokenizer.sep_token]\n",
    "    \n",
    "    phrase_ids=tokenizer.convert_tokens_to_ids(phrase_tokens)\n",
    "    padding_length = max_token_length - len(phrase_ids)\n",
    "    phrase_ids+=[tokenizer.pad_token_id]*padding_length\n",
    "    \n",
    "    return phrase_ids\n",
    "\n",
    "def phrases_tokenization(list_phrases, tokenizer, max_token_length = 128):\n",
    "    \n",
    "    '''This function tansfer phrases' ids into tensors and apply our model's encoder to embed the phrases' ids into high-dimensional vectors'''\n",
    "    \n",
    "    max_token_length = max_token_length\n",
    "    #print(max_token_length)\n",
    "    \n",
    "    ##### -----------> Here is a problem: what about the descriptions with more than 25 words?\n",
    "\n",
    "    \n",
    "    phrases_tokens = [phrase_tokenization(phrase, tokenizer, max_token_length) for phrase in list_phrases]\n",
    "    \n",
    "    #phrases_tensors = [torch.tensor(token) for token in phrases_tokens]\n",
    "    \n",
    "    #phrases_embeddings = [encoder.encode(input_ids=phrase.unsqueeze(0)) for phrase in tqdm(phrases_tensors, position=0, leave=True)]\n",
    "    \n",
    "\n",
    "    return phrases_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d103b951-9b60-474a-9dc4-4284d1dc6ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract test data from dataframe 'df_action_name'.\n",
    "\n",
    "def extract_data(df_action_name, tokenizer, block_size = 128):\n",
    "    \n",
    "    list_actions = df_action_name.to_dict('records')\n",
    "\n",
    "    list_names = [str(action['name_official']).lower() for action in list_actions]\n",
    "    list_descriptions = [str(action['description_official']).lower() for action in list_actions]\n",
    "    list_names_users = [list(action['names_users'].lower().split(',')) for action in list_actions]\n",
    "    #list_names_users = [list(set(action['names_users'].lower().split(','))) for action in list_actions]\n",
    "\n",
    "    list_names_users = [[name.strip() for name in names] for names in list_names_users]\n",
    "    \n",
    "    \n",
    "\n",
    "    names_tokens = phrases_tokenization(list_names, tokenizer, block_size)\n",
    "    descriptions_tokens = phrases_tokenization(list_descriptions, tokenizer, block_size)\n",
    "    list_names_users_tokens = [phrases_tokenization(name[:10], tokenizer, block_size) for name in list_names_users]\n",
    "    \n",
    "    return list_actions,names_tokens,descriptions_tokens,list_names_users_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b6f13fd-f750-41af-bede-695404514b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 756 most frequently applied GitHub Actions has been selected! \n",
      "\n",
      "e.g. Action number 0: \n",
      "\n",
      "Official name: \t\t upload a build artifact\n",
      "Official description:\t upload a build artifact that can be used by subsequent workflow steps \n",
      "\n",
      "With 2944 User-assigned names, give 10 examples:\n",
      "['upload wheelhouse artifact',\n",
      " 'upload pytest log as artifact',\n",
      " 'ðŸ“¤ upload artifact: html',\n",
      " 'archive artifacts (geyser velocity)',\n",
      " 'upload binary files (linux_arm64)',\n",
      " 'upload entitygraphql.aspnet',\n",
      " 'upload test results on failure',\n",
      " 'upload clang-format patch as artifact',\n",
      " 'archive jemalloc binary artifact [centos-8] to github',\n",
      " 'upload test result artifact']\n"
     ]
    }
   ],
   "source": [
    "# show data.\n",
    "\n",
    "print(f'Top {len(list_names)} most frequently applied GitHub Actions has been selected! \\n' )\n",
    "n_example = 0\n",
    "print(f'e.g. Action number {n_example}: \\n')\n",
    "print(f'Official name: \\t\\t {list_names[n_example]}')\n",
    "print(f'Official description:\\t {list_descriptions[n_example]} \\n')\n",
    "print(f'With {len(list_names_users[n_example])} User-assigned names, give 10 examples:')\n",
    "pprint.pprint(list_names_users[n_example][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcb0e4c5-81fb-4a5b-b786-313f1b9cd332",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "actions_train,names_train,descriptions_train,names_users_train = extract_data(df_action_name_train,tokenizer,block_size)\n",
    "actions_test,names_test,descriptions_test,names_users_test = extract_data(df_action_name_test,tokenizer,block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ece8aff-22f7-48b6-b1f1-93ca6c766373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary for with key:value = action:index based on the training dataset.\n",
    "\n",
    "action_index = {}\n",
    "for i in range(len(actions_train)):\n",
    "    action_index[actions_train[i]['action']] = i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2e1d8fb-d83d-4f73-b7f0-0d4d7f17b6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(actions,names_tokens,descriptions_tokens,names_users_tokens,action_index,train=False):\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(actions)):\n",
    "        \n",
    "        if train == True:\n",
    "            X.append(names_tokens[i])\n",
    "            X.append(descriptions_tokens[i])\n",
    "            y.append(action_index[actions[i]['action']])\n",
    "            y.append(action_index[actions[i]['action']])\n",
    "\n",
    "        for j in range(len(names_users_tokens[i])):\n",
    "            X.append(names_users_tokens[i][j])\n",
    "            y.append(action_index[actions[i]['action']])\n",
    "        \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4704c2cc-530b-4f75-9663-eff8b0c1cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_dataset(actions_train,names_train,descriptions_train,names_users_train,action_index,True)\n",
    "X_test, y_test = create_dataset(actions_test,names_test,descriptions_test,names_users_test,action_index,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4511c96d-62bb-431e-86e0-e803a44545b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_dtc = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "clf_dtc.fit(X_train, y_train)\n",
    "clf_dtc_proba = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d670e313-f55e-4f5b-b9ff-ad39b837fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rfc = RandomForestClassifier(random_state=0)\n",
    "clf_rfc.fit(X_train, y_train)\n",
    "clf_rfc_proba = clf_rfc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9e115167-04ac-4921-a497-0973c11f668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(predict_proba,top_n = 3):\n",
    "    \n",
    "    '''\n",
    "    This function sorts the predicted probabilities for each X_test from the highest value to the lowest value\n",
    "    along with their indexes(labels), then returns the top_n indexes(labels) as the output suggested_labels.\n",
    "    '''\n",
    "    \n",
    "    predicted_labels = []\n",
    "\n",
    "    for probas in tqdm(predict_proba, position=0, leave=True):\n",
    "        \n",
    "        predicted_label= []\n",
    "        probas_index = [[proba,index] for index,proba in enumerate(probas)]\n",
    "        predicted_labels.append(sorted(probas_index,reverse=True)[:top_n])\n",
    "        \n",
    "    suggested_labels = [[label[1] for label in labels] for labels in predicted_labels]\n",
    "    \n",
    "    return suggested_labels\n",
    "\n",
    "def blurry_accuracy(predicted_labels, action_index):\n",
    "    '''\n",
    "    This function calculates the performance of the model, it's called 'blurry' because\n",
    "    the output result is considered positive if the real label is predicted correctly in the top_n suggestions.\n",
    "    (the first suggestion doesn't have to be the right one if top_n != 1)\n",
    "    '''\n",
    "    correct = 0\n",
    "    for i in range(len(predicted_labels)):\n",
    "        if action_index[i] in predicted_labels[i]:\n",
    "            correct += 1\n",
    "    return round(correct / len(predicted_labels),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "035aedef-ea31-40b0-b5dc-32a780f462a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 784/784 [00:00<00:00, 3863.76it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 784/784 [00:00<00:00, 3471.33it/s]\n"
     ]
    }
   ],
   "source": [
    "clf_rfc_predicted_labels = predict_labels(clf_rfc_proba,top_n = 3)\n",
    "clf_dtc_predicted_labels = predict_labels(clf_dtc_proba,top_n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "55b102ef-0c67-4a5e-80ff-692720d46f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3265"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blurry_accuracy(clf_dtc_predicted_labels, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe83d64d-77d1-41e8-ab6a-76b1e766a1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
